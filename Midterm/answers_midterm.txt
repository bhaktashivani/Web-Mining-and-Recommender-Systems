{'Q1a': 1.970416294395752, 'Q1b': 2.051966103395068, 'Q2': [2.666035950804163, 2.1542691579943236, 2.0280931357090237], 'Q3a': [[1, 4, 4], [1, 4, 4, 4]], 'Q3b': [1.5608319121482543, 1.5409512373315701, 1.5396484853948416], 'Q4a': [[1, 4, 4, 4, 4, 5, 4.2, 4.2, 4.2, 4.2, 4.2], [1, 0, 4, 0, 4, 0, 4, 0, 4, 0, 5, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]], 'Q4b': [1.5313674357652063, 1.516409245480819], 'Q5a': [1, 121, 0, 4], 'Q5b': [2384, 168945, 86232, 3615, 0.4702652880062319], 'Q6a': [1, 0, 0, 0, 0, 0, 75, 0, 1], 'Q6b': 0.17050724637681158, 'Q7': [0.13345081097468547, 0.13276868273457632, 0.14319766560557823, 0.14268606942549644, 0.1423450053054418, 0.1, 0.2128248428558026], 'Q8': 1.8218848124540317, 'Q9': [1.742012484444442, 2.0366290574931427, 1.4334148860349525], 'Q10': ("If we don't have the item in the training set, we can take the average rating for the given user for other items and return that as a prediction. Therefore, instead of prediction mean of all item, we are getting a geenral idea of how a specific user tends to rate their products. This slightly performs better as there is some correlation there, however it is not much of a difference as expected. It is still in the range from part a to part c MSE from previous part", 1.6696633366192306)}
